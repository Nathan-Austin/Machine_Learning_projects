{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Display Top 5 Rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Display 5 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n",
       "284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19  \\\n",
       "284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n",
       "284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n",
       "284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n",
       "284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n",
       "284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26  \\\n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n",
       "\n",
       "             V27       V28  Amount  Class  \n",
       "284802  0.943651  0.823731    0.77      0  \n",
       "284803  0.068472 -0.053527   24.79      0  \n",
       "284804  0.004455 -0.026561   67.88      0  \n",
       "284805  0.108821  0.104533   10.00      0  \n",
       "284806 -0.002415  0.013649  217.00      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the shape and info, and check for any Null values of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. To make the data useable I scale the data using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "data['Amount']=sc.fit_transform(pd.DataFrame(data['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Drop the time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Re-check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check and remove and duplilcates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9144"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has removed 9144 duplicate values which will allow us to be more precise."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Check for imbalance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1       473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x= data['Class'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Store the feature matrix in X and the Response in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class',axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Check for undersampling and oversampling in the imbalanced dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = data[data['Class']==0]\n",
    "fraud = data[data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275190, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.2 We can see that the sample sizes for normal and fraudulent transactions are not the same.\n",
    "We will resize the normal sample size to match the fraudulent sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample=normal.sample(n=473)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampling_data = pd.concat([normal_sample,fraud],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    473\n",
       "1    473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampling_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.381416</td>\n",
       "      <td>-2.103788</td>\n",
       "      <td>-0.451439</td>\n",
       "      <td>-0.152007</td>\n",
       "      <td>-1.339497</td>\n",
       "      <td>-0.552762</td>\n",
       "      <td>0.352328</td>\n",
       "      <td>-0.284231</td>\n",
       "      <td>-1.128091</td>\n",
       "      <td>0.553644</td>\n",
       "      <td>0.976098</td>\n",
       "      <td>0.710369</td>\n",
       "      <td>0.224465</td>\n",
       "      <td>0.318030</td>\n",
       "      <td>-0.687080</td>\n",
       "      <td>-1.536375</td>\n",
       "      <td>0.073745</td>\n",
       "      <td>1.186847</td>\n",
       "      <td>-0.335489</td>\n",
       "      <td>0.549840</td>\n",
       "      <td>-0.089148</td>\n",
       "      <td>-0.837284</td>\n",
       "      <td>-0.466047</td>\n",
       "      <td>0.416890</td>\n",
       "      <td>0.219656</td>\n",
       "      <td>1.019797</td>\n",
       "      <td>-0.168197</td>\n",
       "      <td>0.076474</td>\n",
       "      <td>1.705625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.499230</td>\n",
       "      <td>-0.406386</td>\n",
       "      <td>-0.681144</td>\n",
       "      <td>-1.187613</td>\n",
       "      <td>1.403295</td>\n",
       "      <td>-2.003143</td>\n",
       "      <td>1.143385</td>\n",
       "      <td>-0.575558</td>\n",
       "      <td>-2.046601</td>\n",
       "      <td>0.244398</td>\n",
       "      <td>-0.994466</td>\n",
       "      <td>-0.080016</td>\n",
       "      <td>0.758245</td>\n",
       "      <td>0.434417</td>\n",
       "      <td>-0.792072</td>\n",
       "      <td>-2.353050</td>\n",
       "      <td>0.116507</td>\n",
       "      <td>0.573407</td>\n",
       "      <td>-0.956974</td>\n",
       "      <td>-0.195066</td>\n",
       "      <td>0.038823</td>\n",
       "      <td>0.368063</td>\n",
       "      <td>-0.193088</td>\n",
       "      <td>0.067790</td>\n",
       "      <td>0.836936</td>\n",
       "      <td>1.024792</td>\n",
       "      <td>-0.165488</td>\n",
       "      <td>-0.045961</td>\n",
       "      <td>-0.093394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.354151</td>\n",
       "      <td>-0.554671</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>-0.696535</td>\n",
       "      <td>-0.782436</td>\n",
       "      <td>-0.944681</td>\n",
       "      <td>-0.289155</td>\n",
       "      <td>-0.293046</td>\n",
       "      <td>-0.916419</td>\n",
       "      <td>0.626756</td>\n",
       "      <td>-0.531162</td>\n",
       "      <td>-0.605261</td>\n",
       "      <td>0.484891</td>\n",
       "      <td>-0.129698</td>\n",
       "      <td>0.660449</td>\n",
       "      <td>1.089699</td>\n",
       "      <td>0.148070</td>\n",
       "      <td>-1.292002</td>\n",
       "      <td>0.636651</td>\n",
       "      <td>0.199159</td>\n",
       "      <td>0.222049</td>\n",
       "      <td>0.477938</td>\n",
       "      <td>-0.205524</td>\n",
       "      <td>0.082426</td>\n",
       "      <td>0.669395</td>\n",
       "      <td>-0.100881</td>\n",
       "      <td>-0.014343</td>\n",
       "      <td>0.016309</td>\n",
       "      <td>-0.106348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.438993</td>\n",
       "      <td>-0.208021</td>\n",
       "      <td>1.342094</td>\n",
       "      <td>-3.428883</td>\n",
       "      <td>-0.301950</td>\n",
       "      <td>0.285281</td>\n",
       "      <td>-0.094299</td>\n",
       "      <td>-0.339602</td>\n",
       "      <td>3.210310</td>\n",
       "      <td>-0.515868</td>\n",
       "      <td>0.411530</td>\n",
       "      <td>-0.170992</td>\n",
       "      <td>-1.958193</td>\n",
       "      <td>-0.611358</td>\n",
       "      <td>1.215162</td>\n",
       "      <td>-0.231702</td>\n",
       "      <td>-1.082752</td>\n",
       "      <td>1.606049</td>\n",
       "      <td>0.948137</td>\n",
       "      <td>-0.405128</td>\n",
       "      <td>0.332481</td>\n",
       "      <td>1.205070</td>\n",
       "      <td>-0.194649</td>\n",
       "      <td>0.269430</td>\n",
       "      <td>-0.508388</td>\n",
       "      <td>-1.004686</td>\n",
       "      <td>-1.314921</td>\n",
       "      <td>-0.091382</td>\n",
       "      <td>-0.277746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.582402</td>\n",
       "      <td>-2.525458</td>\n",
       "      <td>1.420911</td>\n",
       "      <td>-0.644820</td>\n",
       "      <td>-3.673514</td>\n",
       "      <td>1.075919</td>\n",
       "      <td>2.624762</td>\n",
       "      <td>-0.395060</td>\n",
       "      <td>-1.037447</td>\n",
       "      <td>-0.403737</td>\n",
       "      <td>-0.632506</td>\n",
       "      <td>-0.671061</td>\n",
       "      <td>0.841355</td>\n",
       "      <td>-0.682842</td>\n",
       "      <td>1.336203</td>\n",
       "      <td>-0.639692</td>\n",
       "      <td>-0.520186</td>\n",
       "      <td>2.085307</td>\n",
       "      <td>-1.219380</td>\n",
       "      <td>1.618142</td>\n",
       "      <td>0.381425</td>\n",
       "      <td>0.218711</td>\n",
       "      <td>1.941654</td>\n",
       "      <td>0.314239</td>\n",
       "      <td>-0.161898</td>\n",
       "      <td>1.017299</td>\n",
       "      <td>-0.416505</td>\n",
       "      <td>-0.091341</td>\n",
       "      <td>3.173642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.381416 -2.103788 -0.451439 -0.152007 -1.339497 -0.552762  0.352328   \n",
       "1 -0.499230 -0.406386 -0.681144 -1.187613  1.403295 -2.003143  1.143385   \n",
       "2  1.354151 -0.554671  0.018358 -0.696535 -0.782436 -0.944681 -0.289155   \n",
       "3 -1.438993 -0.208021  1.342094 -3.428883 -0.301950  0.285281 -0.094299   \n",
       "4 -1.582402 -2.525458  1.420911 -0.644820 -3.673514  1.075919  2.624762   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0 -0.284231 -1.128091  0.553644  0.976098  0.710369  0.224465  0.318030   \n",
       "1 -0.575558 -2.046601  0.244398 -0.994466 -0.080016  0.758245  0.434417   \n",
       "2 -0.293046 -0.916419  0.626756 -0.531162 -0.605261  0.484891 -0.129698   \n",
       "3 -0.339602  3.210310 -0.515868  0.411530 -0.170992 -1.958193 -0.611358   \n",
       "4 -0.395060 -1.037447 -0.403737 -0.632506 -0.671061  0.841355 -0.682842   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0 -0.687080 -1.536375  0.073745  1.186847 -0.335489  0.549840 -0.089148   \n",
       "1 -0.792072 -2.353050  0.116507  0.573407 -0.956974 -0.195066  0.038823   \n",
       "2  0.660449  1.089699  0.148070 -1.292002  0.636651  0.199159  0.222049   \n",
       "3  1.215162 -0.231702 -1.082752  1.606049  0.948137 -0.405128  0.332481   \n",
       "4  1.336203 -0.639692 -0.520186  2.085307 -1.219380  1.618142  0.381425   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0 -0.837284 -0.466047  0.416890  0.219656  1.019797 -0.168197  0.076474   \n",
       "1  0.368063 -0.193088  0.067790  0.836936  1.024792 -0.165488 -0.045961   \n",
       "2  0.477938 -0.205524  0.082426  0.669395 -0.100881 -0.014343  0.016309   \n",
       "3  1.205070 -0.194649  0.269430 -0.508388 -1.004686 -1.314921 -0.091382   \n",
       "4  0.218711  1.941654  0.314239 -0.161898  1.017299 -0.416505 -0.091341   \n",
       "\n",
       "     Amount  Class  \n",
       "0  1.705625      0  \n",
       "1 -0.093394      0  \n",
       "2 -0.106348      0  \n",
       "3 -0.277746      0  \n",
       "4  3.173642      0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = undersampling_data.drop('Class', axis=1)\n",
    "y = undersampling_data['Class']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.3 split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.4.0 Train the data on differert models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = log.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.4.2 Check the accuracy of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368421052631579"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.4.3 Check the precision score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591836734693877"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.4.4 Check the recall score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9215686274509803"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.4.5 Check the f1 score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9400000000000001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.5.0 Descision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = dt.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.5.1 Check the precision score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9029126213592233"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.5.2 Check the accuracy score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.5.3 Check the recall score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.5.3 Check the F1 score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9073170731707318"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.6.0 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = rf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.6.1 Check the precision score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9680851063829787"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.6.2 Check the accuracy score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9263157894736842"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.6.3 Check the recall score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8921568627450981"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.6.4 Check the F1 score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.7 Make a dataframe to compare the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame({'Models':['LR','DT','RF'],\n",
    "              \"ACC\":[accuracy_score(y_test,y_pred1)*100,\n",
    "                     accuracy_score(y_test,y_pred2)*100,\n",
    "                     accuracy_score(y_test,y_pred3)*100\n",
    "                    ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>93.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>92.631579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Models        ACC\n",
       "0     LR  93.684211\n",
       "1     DT  90.000000\n",
       "2     RF  92.631579"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, Linear Regression and Random Forest have the same accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='Models', ylabel='ACC'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x= final_data['Models'], y= final_data['ACC'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class',axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 29)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use SMOTE (Synthetic Minority Oversampling Technique (SMOTE) is a statistical technique for increasing the number of cases in your dataset in a balanced way. ) to create artificial data to be used in the fraud category. This way I can run the models on larger datasets.\n",
    "For more information about Smote, please refer to http://imbalanced-learn.org/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.1 Resample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res,y_res = SMOTE().fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1    275190\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.2 Split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_res,y_res,test_size=0.20, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3 Run the data through different models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = log.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3.2 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9454831207529344"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3.3 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729922779922779"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3.4 Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9163318364452848"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3.5 f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9438124397254758"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.4 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = dt.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.4.1 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980286347614375"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.4.2 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9971867286191375"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.4.3 Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988727887569769"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.4.4 f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980290465853459"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.5 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = rf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.5.1 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999000690432065"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.5.2 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998000508961356"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.5.3 Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.5.3 F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999000154521575"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.6 Final data for over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame({'Models':['LR','DT','RF'],\n",
    "              \"ACC\":[accuracy_score(y_test,y_pred1)*100,\n",
    "                     accuracy_score(y_test,y_pred2)*100,\n",
    "                     accuracy_score(y_test,y_pred3)*100\n",
    "                    ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>94.548312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.802863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.990007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Models        ACC\n",
       "0     LR  94.548312\n",
       "1     DT  99.802863\n",
       "2     RF  99.990007"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='Models', ylabel='ACC'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x= final_data['Models'],y= final_data['ACC'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_model, open('rf_model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 Load and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = pickle.load(open('rf_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/anaconda3/envs/data_sci/lib/python3.9/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred = rf_model.predict([[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transcation\n"
     ]
    }
   ],
   "source": [
    "if pred == 0:\n",
    "    print(\"Normal Transcation\")\n",
    "else:\n",
    "    print(\"Fraudulent Transcation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 GUI interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import joblib\n",
    "\n",
    "def show_entry_fields():\n",
    "    v1=float(e1.get())\n",
    "    v2=float(e2.get())\n",
    "    v3=float(e3.get())\n",
    "    v4=float(e4.get())\n",
    "    v5=float(e5.get())\n",
    "    v6=float(e6.get())\n",
    "    v7=float(e7.get())\n",
    "    v8=float(e8.get())\n",
    "    v9=float(e9.get())\n",
    "    v10=float(e10.get())\n",
    "    v11=float(e11.get())\n",
    "    v12=float(e12.get())\n",
    "    v13=float(e13.get())\n",
    "    v14=float(e14.get())\n",
    "    v15=float(e15.get())\n",
    "    v16=float(e16.get())\n",
    "    v17=float(e17.get())\n",
    "    v18=float(e18.get())\n",
    "    v19=float(e19.get())\n",
    "    v20=float(e20.get())\n",
    "    v21=float(e21.get())\n",
    "    v22=float(e22.get())\n",
    "    v23=float(e23.get())\n",
    "    v24=float(e24.get())\n",
    "    v25=float(e25.get())\n",
    "    v26=float(e26.get())\n",
    "    v27=float(e27.get())\n",
    "    v28=float(e28.get())\n",
    "    v29=float(e29.get())\n",
    "\n",
    "\n",
    "    model = joblib.load('rf_model.pkl')\n",
    "    y_pred = model.predict([[v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,v11,v12,v13,v14,v15,v16,v17,v18,\n",
    "                                v19,v20,v21,v22,v23,v24,v25,v26,v27,v28,v29]])\n",
    "    list1=[v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,v11,v12,v13,v14,v15,v16,v17,v18,\n",
    "                                v19,v20,v21,v22,v23,v24,v25,v26,v27,v28,v29]\n",
    "\n",
    "    result = []\n",
    "    if y_pred ==0:\n",
    "\n",
    "        result.append(\"Normal Transcation\")\n",
    "    else:\n",
    "\n",
    "        result.append(\"Fraudulent Transcation\")\n",
    "    print(\"######################################\")\n",
    "    print(\"Credit Card Fraud Detection System\", result)\n",
    "    print(\"######################################\")\n",
    "\n",
    "\n",
    "\n",
    "    Label(master, text=\"Final Prediction from the model - credit card fraud detection\").grid(row=31)\n",
    "    Label(master, text=result).grid(row=32)\n",
    "\n",
    "\n",
    "\n",
    "master = Tk()\n",
    "master.title(\"Credit Card Fraud Detection System\")\n",
    "\n",
    "\n",
    "label = Label(master, text = \"Credit Card Fraud Detection System\"\n",
    "                          , bg = \"black\", fg = \"white\",width = 30).grid(row=0,columnspan=2)\n",
    "\n",
    "\n",
    "Label(master, text=\"Enter value of V1\").grid(row=1)\n",
    "Label(master, text=\"Enter value of V2\").grid(row=2)\n",
    "Label(master, text=\"Enter value of V3\").grid(row=3)\n",
    "Label(master, text=\"Enter value of V4\").grid(row=4)\n",
    "Label(master, text=\"Enter value of V5\").grid(row=5)\n",
    "Label(master, text=\"Enter value of V6\").grid(row=6)\n",
    "\n",
    "Label(master, text=\"Enter value of V7\").grid(row=7)\n",
    "Label(master, text=\"Enter value of V8\").grid(row=8)\n",
    "Label(master, text=\"Enter value of V9\").grid(row=9)\n",
    "Label(master, text=\"Enter value of V10\").grid(row=10)\n",
    "Label(master, text=\"Enter value of V11\").grid(row=11)\n",
    "Label(master, text=\"Enter value of V12\").grid(row=12)\n",
    "\n",
    "Label(master, text=\"Enter value of V13\").grid(row=13)\n",
    "Label(master, text=\"Enter value of V14\").grid(row=14)\n",
    "Label(master, text=\"Enter value of V15\").grid(row=15)\n",
    "Label(master, text=\"Enter value of V16\").grid(row=16)\n",
    "Label(master, text=\"Enter value of V17\").grid(row=17)\n",
    "Label(master, text=\"Enter value of V18\").grid(row=18)\n",
    "\n",
    "Label(master, text=\"Enter value of V19\").grid(row=19)\n",
    "Label(master, text=\"Enter value of V20\").grid(row=20)\n",
    "Label(master, text=\"Enter value of V21\").grid(row=21)\n",
    "Label(master, text=\"Enter value of V22\").grid(row=22)\n",
    "Label(master, text=\"Enter value of V23\").grid(row=23)\n",
    "Label(master, text=\"Enter value of V24\").grid(row=24)\n",
    "\n",
    "Label(master, text=\"Enter value of V25\").grid(row=25)\n",
    "Label(master, text=\"Enter value of V26\").grid(row=26)\n",
    "Label(master, text=\"Enter value of V27\").grid(row=27)\n",
    "Label(master, text=\"Enter value of V28\").grid(row=28)\n",
    "Label(master, text=\"Enter value of V29\").grid(row=29)\n",
    "\n",
    "e1 = Entry(master)\n",
    "e2 = Entry(master)\n",
    "e3 = Entry(master)\n",
    "e4 = Entry(master)\n",
    "e5 = Entry(master)\n",
    "e6 = Entry(master)\n",
    "\n",
    "e7 = Entry(master)\n",
    "e8 = Entry(master)\n",
    "e9 = Entry(master)\n",
    "e10 = Entry(master)\n",
    "e11 = Entry(master)\n",
    "e12 = Entry(master)\n",
    "\n",
    "e13 = Entry(master)\n",
    "e14 = Entry(master)\n",
    "e15 = Entry(master)\n",
    "e16 = Entry(master)\n",
    "e17 = Entry(master)\n",
    "e18= Entry(master)\n",
    "\n",
    "e19 = Entry(master)\n",
    "e20 = Entry(master)\n",
    "e21 = Entry(master)\n",
    "e22 = Entry(master)\n",
    "e23= Entry(master)\n",
    "e24 = Entry(master)\n",
    "\n",
    "\n",
    "e25 = Entry(master)\n",
    "e26= Entry(master)\n",
    "e27 = Entry(master)\n",
    "e28 = Entry(master)\n",
    "e29= Entry(master)\n",
    "\n",
    "e1.grid(row=1, column=1)\n",
    "e2.grid(row=2, column=1)\n",
    "e3.grid(row=3, column=1)\n",
    "e4.grid(row=4, column=1)\n",
    "e5.grid(row=5, column=1)\n",
    "e6.grid(row=6, column=1)\n",
    "\n",
    "e7.grid(row=7, column=1)\n",
    "e8.grid(row=8, column=1)\n",
    "e9.grid(row=9, column=1)\n",
    "e10.grid(row=10, column=1)\n",
    "e11.grid(row=11, column=1)\n",
    "e12.grid(row=12, column=1)\n",
    "\n",
    "\n",
    "e13.grid(row=13, column=1)\n",
    "e14.grid(row=14, column=1)\n",
    "e15.grid(row=15, column=1)\n",
    "e16.grid(row=16, column=1)\n",
    "e17.grid(row=17, column=1)\n",
    "e18.grid(row=18, column=1)\n",
    "\n",
    "\n",
    "e19.grid(row=19, column=1)\n",
    "e20.grid(row=20, column=1)\n",
    "e21.grid(row=21, column=1)\n",
    "e22.grid(row=22, column=1)\n",
    "e23.grid(row=23, column=1)\n",
    "e24.grid(row=24, column=1)\n",
    "\n",
    "e25.grid(row=25, column=1)\n",
    "e26.grid(row=26, column=1)\n",
    "e27.grid(row=27, column=1)\n",
    "e28.grid(row=28, column=1)\n",
    "e29.grid(row=29, column=1)\n",
    "\n",
    "Button(master, text='Predict', command=show_entry_fields).grid(row=30, column=1, sticky=W, pady=4)\n",
    "\n",
    "mainloop( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c05337e2f67a4c2cb1d01a3df3889a12932927617aa3b5bca76b901f8124511a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
